{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88999733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "#graphing\n",
    "import matplotlib.pyplot as plt\n",
    "#stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from sklearn.mixture import GaussianMixture \n",
    "#import testing\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import selection_tests\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafc4a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_stata(\"all_plans_c_bonus.dta\")\n",
    "\n",
    "data['log_enroll'] = np.log(data['enr_c'])\n",
    "data['enr_total'] = data['enr_c'] + data['enr_FFS']\n",
    "data['penetration'] = data['enr_c']/data['enr_total']\n",
    "data['bmFFS_ns_diff'] = data['bm_ns'] - data['bmFFS']\n",
    "#data = data[ (data['year'] >= 2006) & (data['year'] <= 2016) ]\n",
    "\n",
    "print(data['year'].min())\n",
    "\n",
    "#data.to_stata('all_plans_c_stata.dta')\n",
    "\n",
    "#create a variable that is just db \n",
    "treat = data[['ssa', 'state', 'county', 'double_bonus']].copy()\n",
    "treat = treat.groupby(['ssa', 'state', 'county'],as_index=False).max()\n",
    "treat = treat.rename(columns={'double_bonus':'treatment' })\n",
    "data = data.merge(treat, on=['ssa', 'state', 'county'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7c5254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09675879776477814\n",
      "0.2912343442440033\n",
      "------------------\n",
      "------------------\n",
      "0.15043731\n",
      "0.29852337\n",
      "------------------\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "print(data[  (data['treatment']==0) & (data['year']<2012) ]['penetration'].mean())\n",
    "print(data[  (data['treatment']==1) & (data['year']<2012) ]['penetration'].mean())\n",
    "\n",
    "print('------------------')\n",
    "print('------------------')\n",
    "\n",
    "no_bonus_pre = data[  (data['treatment']==0) & (data['year']<2012) ]\n",
    "bonus_pre = data[  (data['treatment']==1) & (data['year']<2012) ]\n",
    "print( (no_bonus_pre['penetration']*no_bonus_pre['enr_total']).sum()/no_bonus_pre['enr_total'].sum() )\n",
    "print( (bonus_pre['penetration']*bonus_pre['enr_total']).sum()/bonus_pre['enr_total'].sum() )\n",
    "\n",
    "print('------------------')\n",
    "print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14255a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{double\\_bonus} & 0.0339  & 0.1809 \\\\\n",
      "\\textbf{bm\\_ns} & 818.4683  & 76.3584 \\\\\n",
      "\\textbf{bmFFS\\_ns\\_diff} & -11.2980  & 16.9155 \\\\\n",
      "\\textbf{star\\_C2} & 7.6048  & 13.5177 \\\\\n",
      "\\textbf{ins\\_parent\\_noSNPs} & 2.9230  & 1.7621 \\\\\n",
      "\\textbf{FFS\\_AB} & 714.8803  & 107.1201 \\\\\n",
      "\\textbf{unemploy\\_rt} & 6.8141  & 2.9020 \\\\\n",
      "\\textbf{pc\\_income} & 36.2201  & 10.2391 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & -4.0951  & 7.4628 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & -9.2093  & 12.9338 \\\\\n",
      "\\textbf{risk\\_FFS} & 0.9625  & 0.0711 \\\\\n",
      "\\textbf{risk\\_pub\\_c} & 0.9196  & 0.1184 \\\\\n",
      "\\textbf{rebate\\_pub\\_c} & 48.7655  & 33.0495 \\\\\n"
     ]
    }
   ],
   "source": [
    "summary_xs1=['double_bonus', 'bm_ns','bmFFS_ns_diff','star_C2',  'ins_parent_noSNPs',  'FFS_AB', \n",
    "                           'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'risk_FFS',\n",
    "                           'risk_pub_c', 'rebate_pub_c']\n",
    "\n",
    "def join_print(t1,t2,\n",
    "               summary_xs=summary_xs1 ):\n",
    "    table =  pd.DataFrame(index=summary_xs)\n",
    "    table['1'] = t1\n",
    "    table['2'] = t2\n",
    "    \n",
    "    for row in table.itertuples():\n",
    "        listrow = list(row)\n",
    "        print('\\\\textbf{%s}'%listrow[0].replace('_','\\\\_'),end='')\n",
    "        for i in range(len(listrow)-1):\n",
    "            print(' & %.4f '%listrow[i+1],end='')\n",
    "        print('\\\\\\\\')\n",
    "\n",
    "join_print(data[summary_xs1].mean(),data[summary_xs1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4d2936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statsmodels.org/dev/examples/notebooks/generated/glm_weights.html\n",
    "\n",
    "def drop_data(data,y_name,x_name,absorb=None):\n",
    "    data = data.copy()\n",
    "    data = data[y_name + x_name + absorb]\n",
    "    missing_vals = ~data.isnull().max(axis=1)\n",
    "    data = data[missing_vals]\n",
    "    data = data[data['year'].groupby(data['ssa']).transform('count')>=11]\n",
    "    return data\n",
    "    \n",
    "\n",
    "def demean(y_name,x_name,data=None,absorb=None,cluster=None): \n",
    "\n",
    "    y,X = data[ y_name], data[ x_name ]\n",
    "    \n",
    "    y_dot = y.copy()\n",
    "    X_dot = X.copy()\n",
    "    \n",
    "    ybar = y.mean()\n",
    "    Xbar = X.mean()\n",
    "\n",
    "    \n",
    "    for effect in absorb:\n",
    "        y_dot = y_dot - y.groupby(data[effect]).transform('mean')\n",
    "        X_dot = X_dot - X.groupby(data[effect]).transform('mean')\n",
    "    y_dot = y_dot + ybar\n",
    "    X_dot = X_dot + Xbar\n",
    "    return y_dot, X_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00861d9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ins_parent_noSNPs', 'star_C2', 'bm_ns', 'FFS_AB', 'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'double_bonus', 'bmFFS_ns_diff']\n",
      "                   params 1      se 1  params 2      se 2\n",
      "ins_parent_noSNPs  0.001379  0.000220  0.001093  0.000222\n",
      "star_C2           -0.000048  0.000030 -0.000052  0.000030\n",
      "bm_ns                   NaN       NaN -0.000067  0.000007\n",
      "FFS_AB            -0.000080  0.000006 -0.000057  0.000007\n",
      "unemploy_rt       -0.004876  0.000299 -0.004996  0.000299\n",
      "pc_income         -0.000567  0.000081 -0.000854  0.000084\n",
      "log_risk_FFS       0.000847  0.000122  0.000847  0.000122\n",
      "log_risk_pub_c     0.000293  0.000050  0.000340  0.000050\n",
      "double_bonus       0.005642  0.001024       NaN       NaN\n",
      "bmFFS_ns_diff     -0.000287  0.000020 -0.000281  0.000019\n"
     ]
    }
   ],
   "source": [
    "model1_x = ['double_bonus','bmFFS_ns_diff','star_C2','log_risk_pub_c',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']\n",
    "\n",
    "model2_x = ['bm_ns','bmFFS_ns_diff','star_C2','log_risk_pub_c',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']\n",
    "    \n",
    "\n",
    "model_xs = [model1_x,model2_x]\n",
    "\n",
    "\n",
    "\n",
    "def setup_data(y_name,model_xs,data):\n",
    "     #get the super set of all the model names\n",
    "    all_xs = set()\n",
    "    for model_x in model_xs:\n",
    "        all_xs = all_xs.union(set(model_x))\n",
    "    all_xs = list(all_xs)\n",
    "    \n",
    "    #subtract out the columns that are not in the data\n",
    "    x_name = []\n",
    "    for col in data.columns:\n",
    "        if col in all_xs:\n",
    "            x_name.append(col)\n",
    "    print(x_name)\n",
    "    \n",
    "    #clean the data\n",
    "    y_dot, X_dot = demean(y_name,x_name, data=data,absorb=['ssa','year'])\n",
    "    missing_vals = ~data[y_name + x_name].isnull().max(axis=1)\n",
    "    y_dot, X_dot = y_dot[missing_vals],X_dot[missing_vals]\n",
    "    \n",
    "    return y_dot,X_dot,x_name,missing_vals\n",
    "\n",
    "\n",
    "\n",
    "def return_results(y_name,model_xs,data,weights=True):\n",
    "    y_dot,X_dot,x_name,missing_vals = setup_data(y_name,model_xs,data)\n",
    "    params = []\n",
    "    se = []\n",
    "    for model_x in model_xs:\n",
    "        if weights:\n",
    "            var_weights = np.array( data['enr_total'][missing_vals] )\n",
    "            X_dot_m = X_dot[model_x].copy()\n",
    "            model = sm.GLM(y_dot,X_dot_m,var_weights=var_weights)\n",
    "            model_fit = model.fit()\n",
    "            params.append(model_fit.params)\n",
    "            se.append(model_fit.bse)\n",
    "    table  = pd.DataFrame(index=x_name)\n",
    "    col_names = []\n",
    "    for i in range(len(model_xs)):\n",
    "        table['params %i'%(i+1)]  = params[i]\n",
    "        table['se %i'%(i+1)]  = se[i]\n",
    "    return table\n",
    "    \n",
    "\n",
    "table = return_results(['penetration'],model_xs,data)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc63f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcc|cc}\n",
      "\\toprule\n",
      "{}& \\textbf{coef 1} & \\textbf{se 1}& \\textbf{coef 2} & \\textbf{se 2}\\\\\n",
      "\\midrule\n",
      "\\textbf{ins\\_parent\\_noSNPs} & 0.0014  & 0.0002  & 0.0011  & 0.0002 \\\\\n",
      "\\textbf{star\\_C2} & -0.0000  & 0.0000  & -0.0001  & 0.0000 \\\\\n",
      "\\textbf{bm\\_ns} & nan  & nan  & -0.0001  & 0.0000 \\\\\n",
      "\\textbf{FFS\\_AB} & -0.0001  & 0.0000  & -0.0001  & 0.0000 \\\\\n",
      "\\textbf{unemploy\\_rt} & -0.0049  & 0.0003  & -0.0050  & 0.0003 \\\\\n",
      "\\textbf{pc\\_income} & -0.0006  & 0.0001  & -0.0009  & 0.0001 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & 0.0008  & 0.0001  & 0.0008  & 0.0001 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & 0.0003  & 0.0001  & 0.0003  & 0.0001 \\\\\n",
      "\\textbf{double\\_bonus} & 0.0056  & 0.0010  & nan  & nan \\\\\n",
      "\\textbf{bmFFS\\_ns\\_diff} & -0.0003  & 0.0000  & -0.0003  & 0.0000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "def table_to_latex(table):\n",
    "    num_col = len(table.columns)\n",
    "    print('\\\\begin{tabular}{l',end='')\n",
    "    for i in range(int(len(table.columns)/2-1)):\n",
    "        print('cc|',end='')\n",
    "    print('cc}')\n",
    "    print('\\\\toprule')\n",
    "    print('{}',end='')\n",
    "    model = 1\n",
    "    while model <= len(table.columns)/2:\n",
    "        print('& \\\\textbf{coef %s} & \\\\textbf{se %s}'%(model,model),end='' )\n",
    "        model = model +1 \n",
    "    print('\\\\\\\\')\n",
    "    print('\\\\midrule')\n",
    "\n",
    "    \n",
    "    for row in table.itertuples():\n",
    "        listrow = list(row)\n",
    "        print('\\\\textbf{%s}'%listrow[0].replace('_','\\\\_'),end='')\n",
    "        for i in range(len(listrow)-1):\n",
    "            print(' & %.4f '%listrow[i+1],end='')\n",
    "        print('\\\\\\\\')\n",
    "    print('\\\\bottomrule')\n",
    "    print('\\\\end{tabular}')\n",
    "    \n",
    "table_to_latex(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9047720e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['ins_parent_noSNPs', 'star_C2', 'bm_ns', 'FFS_AB', 'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'double_bonus', 'bmFFS_ns_diff']\n",
      "\\begin{center}\n",
      "\\begin{tabular}{ccccc}\n",
      "\\toprule\n",
      "\\textbf{Version} & \\textbf{Result} & \\textbf{90 \\% CI} & \\textbf{95 \\% CI} & \\textbf{99 \\% CI} \\\\ \\midrule\n",
      "Shi (2015) & H0 & [-4.499, 0.274] & [-6.815, 2.589] & [-12.845, 8.620] \\\\\n",
      "Classical & H2 & [-3.828, -0.538] & [-4.142, -0.224] & [-4.759, 0.393] \\\\\n",
      "Bootstrap & H0 & [-3.832, -0.365] & [-4.234, -0.070] & [-5.068, 0.650] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "None\n",
      "[[('ll1', 'll2'), -2.1832269579474612, 95, 85, 95]]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import selection_tests\n",
    "\n",
    "\n",
    "class GLS_LL(GenericLikelihoodModel):\n",
    "\n",
    "    def __init__(self, *args, model=None, **kwargs):\n",
    "        super(GLS_LL, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def loglikeobs(self, params, scale=None):\n",
    "        \"\"\"\n",
    "        Evaluate the log-likelihood for a generalized linear model.\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        scale = sm.tsa.stattools.float_like(scale, \"scale\", optional=True)\n",
    "        lin_pred = np.dot(model.exog, params) + model._offset_exposure\n",
    "        expval = model.family.link.inverse(lin_pred)\n",
    "        if scale is None:\n",
    "            scale = model.estimate_scale(expval)\n",
    "        llf = model.family.loglike_obs(model.endog, expval, model.var_weights,\n",
    "                                  scale)\n",
    "        return llf\n",
    "\n",
    "\n",
    "\n",
    "#this is janky as f.... need to fix it...\n",
    "def setup_test(y_dot,X_dot,\n",
    "    model1_cov = [],\n",
    "    model2_cov = []):\n",
    "    \n",
    "    #model 1\n",
    "    #weights = np.array( data['enr_c_mean'][missing_vals] )\n",
    "    m1 = sm.GLM(y_dot,X_dot[model1_cov])#,var_weights=weights)\n",
    "    m1_fit = m1.fit()\n",
    "\n",
    "    #model2\n",
    "    m2 = sm.GLM(y_dot,X_dot[model2_cov])#,var_weights=weights)\n",
    "    m2_fit = m2.fit()\n",
    "\n",
    "    model1 = GLS_LL(y_dot, X_dot[model1_cov], model=m1)\n",
    "    ll1 = model1.loglikeobs(m1_fit.params)\n",
    "    grad1 = model1.score_obs(m1_fit.params)\n",
    "    hess1 = model1.hessian(m1_fit.params)\n",
    "    params1 = m1_fit.params\n",
    "\n",
    "    model2 = GLS_LL(y_dot, X_dot[model2_cov], model=m2)\n",
    "\n",
    "    ll2 = model2.loglikeobs(m2_fit.params)\n",
    "    grad2 = model2.score_obs(m2_fit.params)\n",
    "    hess2 = model2.hessian(m2_fit.params)\n",
    "    params2 = m2_fit.params\n",
    "    \n",
    "    return  ll1, grad1, hess1, params1, ll2, grad2, hess2, params2\n",
    "\n",
    "\n",
    "\n",
    "def pairwise_tests(y_name,model_xs,data):\n",
    "    y_dot,X_dot,x_name,missing_vals = setup_data(y_name,model_xs,data)\n",
    "    \n",
    "    \n",
    "    #TODO fix this so that it does all the comparison\n",
    "    combos = list(itertools.combinations(model_xs,2))\n",
    "    labels = [ 'll'+ str(i+1) for i in range(len(model_xs))]\n",
    "    label_combos = list(itertools.combinations(labels,2))\n",
    "    res = []\n",
    "    for i in range(len(combos)):\n",
    "        combo = combos[i]\n",
    "        label_combo = label_combos[i]\n",
    "        model1_x = combo[0]\n",
    "        model2_x = combo[1]\n",
    "        setup_test_i = lambda yn,xn : setup_test(yn,xn,model1_cov = model1_x, model2_cov= model2_x)\n",
    "        test_stat,res1,res2,res3 = selection_tests.test_results(y_dot,X_dot,setup_test_i)\n",
    "        \n",
    "        print(selection_tests.test_table(y_dot,X_dot,setup_test_i))\n",
    "        \n",
    "        res.append( [label_combo,test_stat,res1,res2,res3])\n",
    "    #print_pairwise_tests(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = pairwise_tests(['log_enroll'],model_xs,data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23318b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e69da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a7e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
