{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88999733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "#graphing\n",
    "import matplotlib.pyplot as plt\n",
    "#stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from sklearn.mixture import GaussianMixture \n",
    "#import testing\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import selection_tests\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb73fe9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index   ssa  state  county  enr_FFS  enr_c  hhi_ins  hhi_ins_noSNP  \\\n",
      "year                                                                       \n",
      "2006   2581  2581   2581    2581     2581   2581     2581           2581   \n",
      "2007   2753  2753   2753    2753     2753   2753     2753           2753   \n",
      "2008   2818  2818   2818    2818     2818   2818     2818           2818   \n",
      "2009   2805  2805   2805    2805     2805   2805     2805           2805   \n",
      "2010   2813  2813   2813    2813     2813   2813     2813           2813   \n",
      "2011   2806  2806   2806    2806     2806   2806     2806           2806   \n",
      "2012   2788  2788   2788    2788     2788   2788     2788           2788   \n",
      "2013   2778  2778   2778    2778     2778   2778     2778           2778   \n",
      "2014   2663  2663   2663    2663     2663   2663     2663           2663   \n",
      "2015   2653  2653   2653    2653     2653   2653     2653           2653   \n",
      "2016   2645  2645   2645    2645     2645   2645     2645           2645   \n",
      "2017   2599  2599   2599    2599     2599   2599     2599           2599   \n",
      "\n",
      "      ins_parent  ins_parent_noSNPs  ...  post  post_bmFFS  risk_pub_c_std  \\\n",
      "year                                 ...                                     \n",
      "2006        2581               2581  ...  2581        2581            2581   \n",
      "2007        2753               2753  ...  2753        2753            2753   \n",
      "2008        2818               2818  ...  2818        2818            2818   \n",
      "2009        2805               2805  ...  2805        2805            2805   \n",
      "2010        2813               2813  ...  2813        2813            2813   \n",
      "2011        2806               2806  ...  2806        2806            2806   \n",
      "2012        2788               2788  ...  2788        2788            2788   \n",
      "2013        2778               2778  ...  2778        2778            2778   \n",
      "2014        2663               2663  ...  2663        2663            2663   \n",
      "2015        2653               2653  ...  2653        2653            2653   \n",
      "2016        2645               2645  ...  2645        2645            2645   \n",
      "2017        2599               2599  ...  2599        2599            2599   \n",
      "\n",
      "      risk_pub_p_std  risk_FFS_std  log_risk_FFS  log_risk_pub_c  \\\n",
      "year                                                               \n",
      "2006            2581          2581          2581            2581   \n",
      "2007            2753          2753          2753            2753   \n",
      "2008            2818          2818          2818            2818   \n",
      "2009            2805          2805          2805            2805   \n",
      "2010            2813          2813          2813            2813   \n",
      "2011            2806          2806          2806            2806   \n",
      "2012            2788          2788          2788            2788   \n",
      "2013            2778          2778          2778            2778   \n",
      "2014            2663          2663          2663            2663   \n",
      "2015            2653          2653          2653            2653   \n",
      "2016            2645          2645          2645            2645   \n",
      "2017            2599          2599          2599            2599   \n",
      "\n",
      "      log_risk_pub_p  count  double_bonus  \n",
      "year                                       \n",
      "2006            2581   2581          2581  \n",
      "2007            2753   2753          2753  \n",
      "2008            2818   2818          2818  \n",
      "2009            2805   2805          2805  \n",
      "2010            2813   2813          2813  \n",
      "2011            2806   2806          2806  \n",
      "2012            2788   2788          2788  \n",
      "2013            2778   2778          2778  \n",
      "2014            2663   2663          2663  \n",
      "2015            2653   2653          2653  \n",
      "2016            2645   2645          2645  \n",
      "2017            2599   2599          2599  \n",
      "\n",
      "[12 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "#figure out a list of plans that occur every year\n",
    "def make_balanced():\n",
    "    data = pd.read_stata(\"all_plans_c_bonus.dta\")\n",
    "    data = data[ (data['year'] >= 2006) & (data['year'] <= 2016)]\n",
    "\n",
    "    ssa_unique = list(data['ssa'][data['year']==2006].unique())\n",
    "    for year in range(2006,2017):\n",
    "\n",
    "        ssa_year = list(data[data['year']==year]['ssa'].unique())\n",
    "        ssa_unique_copy = []\n",
    "        for ssa in ssa_unique:\n",
    "            if ssa in ssa_year:\n",
    "                ssa_unique_copy.append(ssa)\n",
    "        ssa_unique = ssa_unique_copy\n",
    "\n",
    "    data = data[data['ssa'].apply(lambda x : x in ssa_unique)]\n",
    "    data.to_stata(\"all_plans_c_bonus_balanced.dta\")\n",
    "    \n",
    "#make_balanced()\n",
    "\n",
    "data = pd.read_stata(\"all_plans_c_bonus.dta\")\n",
    "print(data.groupby('year').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1da2f411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5590, 5600, 10040, 19180, 19370, 24010, 24690, 39330, 45030, 45130]\n"
     ]
    }
   ],
   "source": [
    "#drop counties with double bonus 2016?\n",
    "status_2016 = []\n",
    "list_2016 = list( data[ (data['double_bonus'] == 1) & (data['year'] == 2016) ]['ssa'] )\n",
    "list_2015 = list( data[ (data['double_bonus'] == 0) & (data['year'] == 2015) ]['ssa'] )\n",
    "for ssa in list_2016:\n",
    "    if ssa in list_2015:\n",
    "        status_2016.append(ssa)\n",
    "print(status_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dafc4a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32582, 80)\n",
      "Index(['index', 'ssa', 'state', 'county', 'year', 'enr_FFS', 'enr_c',\n",
      "       'hhi_ins', 'hhi_ins_noSNP', 'ins_parent', 'ins_parent_noSNPs',\n",
      "       'ins_plans', 'HMO_share', 'PPO_share', 'qual_2012', 'qual_2013',\n",
      "       'qual_2014', 'qual_2015', 'partaenrollment', 'partb_enrollment',\n",
      "       'prescription_drugs', 'prev_comp_dental', 'eye_exams', 'hearing_exams',\n",
      "       'deductible', 'partb_premium', 'plan_premium', 'partd_premium', 'OOPC',\n",
      "       'risk_pub_p', 'bid_pub_p', 'rebate_pub_p', 'risk_pub_c', 'bid_pub_c',\n",
      "       'rebate_pub_c', 'star_C2', 'star_CD2', 'bmFFS', 'bm_ns', 'risk_FFS',\n",
      "       'FFS_AB', 'FFS_AB_rs', 'buydown', 'OOPC_noprem', 'extras', 'quartile',\n",
      "       'bid_pub_p_nominal', 'bid_pub_c_nominal', 'rebate_pub_p_nominal',\n",
      "       'rebate_pub_c_nominal', 'bmFFS_nominal', 'FFS_AB_nominal',\n",
      "       'bm_ns_nominal', 'OOPC_nominal', 'plan_premium_nominal',\n",
      "       'partd_premium_nominal', 'buydown_nominal', 'rebate_std',\n",
      "       'benchmark_diff', 'benchmark_diff_n', 'benchmark_diff_ns', 'quart_yr',\n",
      "       'quart2', 'total_premium', 'rural_urban', 'unemploy_rt', 'pc_income',\n",
      "       'partD', 'enr_c_mean', 'st', 'post', 'post_bmFFS', 'risk_pub_c_std',\n",
      "       'risk_pub_p_std', 'risk_FFS_std', 'log_risk_FFS', 'log_risk_pub_c',\n",
      "       'log_risk_pub_p', 'count', 'double_bonus', 'log_enroll', 'enr_total',\n",
      "       'bmFFS_ns_diff', 'treatment', 'treat*trend', 'control*trend',\n",
      "       'treat2*trend'],\n",
      "      dtype='object')\n",
      "831.8660278320312\n",
      "831.9771118164062\n",
      "benchmark_diff        -4.669830\n",
      "benchmark_diff_n       9.118794\n",
      "benchmark_diff_ns     -6.614505\n",
      "bmFFS                831.977112\n",
      "dtype: float32\n",
      "7.999172210693359\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_stata(\"all_plans_c_bonus.dta\")\n",
    "\n",
    "#drop ssas that gained status in 2016\n",
    "for ssa in status_2016:\n",
    "    data = data[data['ssa']!=ssa]\n",
    "print(data.shape)\n",
    "\n",
    "data['log_enroll'] = np.log(data['enr_c'])\n",
    "data['enr_total'] = data['enr_c'] + data['enr_FFS']\n",
    "data['bmFFS_ns_diff'] = data['bmFFS'] - data['bm_ns']\n",
    "data = data[ (data['year'] >= 2006) & (data['year'] <= 2016)]\n",
    "\n",
    "#create a variable that is just db \n",
    "treat = data[['ssa', 'state', 'county', 'double_bonus']].copy()\n",
    "treat = treat.groupby(['ssa', 'state', 'county'],as_index=False).max()\n",
    "treat = treat.rename(columns={'double_bonus':'treatment' })\n",
    "data = data.merge(treat, on=['ssa', 'state', 'county'],how='left')\n",
    "\n",
    "\n",
    "#create interaction with year and db\n",
    "data['treat*trend'] = data['treatment']*(data['year']<=2012)\n",
    "data['control*trend'] = (1-data['treatment'])*(data['year']<=2012)\n",
    "\n",
    "\n",
    "data['treat2*trend'] = data['bm_ns']*(data['year'])*(data['year']<=2012)\n",
    "\n",
    "\n",
    "print(data.columns)\n",
    "print(data[data['double_bonus']==1]['bmFFS'].mean())\n",
    "print(data['bmFFS'].mean())\n",
    "print(data[['benchmark_diff',\n",
    "           'benchmark_diff_n',\n",
    "           'benchmark_diff_ns',\n",
    "           'bmFFS']].mean())\n",
    "\n",
    "print(data['star_C2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14255a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{double\\_bonus} & 0.0364  & 0.1873 \\\\\n",
      "\\textbf{bm\\_ns} & 820.8596  & 77.7560 \\\\\n",
      "\\textbf{bmFFS\\_ns\\_diff} & 11.1202  & 16.7403 \\\\\n",
      "\\textbf{star\\_C2} & 7.9992  & 14.1902 \\\\\n",
      "\\textbf{ins\\_parent\\_noSNPs} & 2.9391  & 1.7732 \\\\\n",
      "\\textbf{FFS\\_AB} & 715.3871  & 108.4759 \\\\\n",
      "\\textbf{unemploy\\_rt} & 7.0005  & 2.9172 \\\\\n",
      "\\textbf{pc\\_income} & 35.7116  & 9.9795 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & -4.2276  & 7.4634 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & -9.8988  & 12.8545 \\\\\n",
      "\\textbf{risk\\_FFS} & 0.9613  & 0.0710 \\\\\n",
      "\\textbf{risk\\_pub\\_c} & 0.9132  & 0.1170 \\\\\n",
      "\\textbf{rebate\\_pub\\_c} & 48.8873  & 32.9391 \\\\\n"
     ]
    }
   ],
   "source": [
    "summary_xs1=['double_bonus', 'bm_ns','bmFFS_ns_diff','star_C2',  'ins_parent_noSNPs',  'FFS_AB', \n",
    "                           'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'risk_FFS',\n",
    "                           'risk_pub_c', 'rebate_pub_c']\n",
    "\n",
    "def join_print(t1,t2,\n",
    "               summary_xs=summary_xs1 ):\n",
    "    table =  pd.DataFrame(index=summary_xs)\n",
    "    table['1'] = t1\n",
    "    table['2'] = t2\n",
    "    \n",
    "    for row in table.itertuples():\n",
    "        listrow = list(row)\n",
    "        print('\\\\textbf{%s}'%listrow[0].replace('_','\\\\_'),end='')\n",
    "        for i in range(len(listrow)-1):\n",
    "            print(' & %.4f '%listrow[i+1],end='')\n",
    "        print('\\\\\\\\')\n",
    "\n",
    "join_print(data[summary_xs1].mean(),data[summary_xs1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4d2936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statsmodels.org/dev/examples/notebooks/generated/glm_weights.html\n",
    "\n",
    "def drop_data(data,y_name,x_name,absorb=None):\n",
    "    data = data.copy()\n",
    "    data = data[y_name + x_name + absorb]\n",
    "    missing_vals = ~data.isnull().max(axis=1)\n",
    "    data = data[missing_vals]\n",
    "    data = data[data['year'].groupby(data['ssa']).transform('count')>=11]\n",
    "    return data\n",
    "    \n",
    "\n",
    "def demean(y_name,x_name,data=None,absorb=None,cluster=None): \n",
    "\n",
    "    y,X = data[ y_name], data[ x_name ]\n",
    "    \n",
    "    y_dot = y.copy()\n",
    "    X_dot = X.copy()\n",
    "    \n",
    "    ybar = y.mean()\n",
    "    Xbar = X.mean()\n",
    "\n",
    "    \n",
    "    for effect in absorb:\n",
    "        y_dot = y_dot - y.groupby(data[effect]).transform('mean')\n",
    "        X_dot = X_dot - X.groupby(data[effect]).transform('mean')\n",
    "    y_dot = y_dot + ybar\n",
    "    X_dot = X_dot + Xbar\n",
    "    return y_dot, X_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00861d9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ins_parent_noSNPs', 'star_C2', 'bm_ns', 'FFS_AB', 'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'double_bonus', 'bmFFS_ns_diff', 'treat*trend', 'control*trend', 'treat2*trend']\n"
     ]
    }
   ],
   "source": [
    "model1_x = ['double_bonus','treat*trend','control*trend','bmFFS_ns_diff','star_C2','log_risk_pub_c',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']\n",
    "\n",
    "model2_x = ['bm_ns','treat2*trend','bmFFS_ns_diff','star_C2','log_risk_pub_c',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']\n",
    "    \n",
    "\n",
    "model_xs = [model1_x,model2_x]\n",
    "\n",
    "\n",
    "\n",
    "def setup_data(y_name,model_xs,data):\n",
    "     #get the super set of all the model names\n",
    "    all_xs = set()\n",
    "    for model_x in model_xs:\n",
    "        all_xs = all_xs.union(set(model_x))\n",
    "    all_xs = list(all_xs)\n",
    "    \n",
    "    #subtract out the columns that are not in the data\n",
    "    x_name = []\n",
    "    for col in data.columns:\n",
    "        if col in all_xs:\n",
    "            x_name.append(col)\n",
    "    print(x_name)\n",
    "    \n",
    "    #clean the data\n",
    "    y_dot, X_dot = demean(y_name,x_name, data=data,absorb=['ssa','year'])\n",
    "    missing_vals = ~data[y_name + x_name].isnull().max(axis=1)\n",
    "    y_dot, X_dot = y_dot[missing_vals],X_dot[missing_vals]\n",
    "    \n",
    "    return y_dot,X_dot,x_name,missing_vals\n",
    "\n",
    "\n",
    "\n",
    "def return_results(y_name,model_xs,data,weights=True):\n",
    "    y_dot,X_dot,x_name,missing_vals = setup_data(y_name,model_xs,data)\n",
    "    params = []\n",
    "    se = []\n",
    "    for model_x in model_xs:\n",
    "        if weights:\n",
    "            var_weights = np.array( data['enr_c'][missing_vals] )\n",
    "            X_dot_m = X_dot[model_x].copy()\n",
    "            model = sm.GLM(y_dot,X_dot_m,var_weights=var_weights)\n",
    "            model_fit = model.fit()\n",
    "            params.append(model_fit.params)\n",
    "            se.append(model_fit.bse)\n",
    "    table  = pd.DataFrame(index=x_name)\n",
    "    col_names = []\n",
    "    for i in range(len(model_xs)):\n",
    "        table['params %i'%(i+1)]  = params[i]\n",
    "        table['se %i'%(i+1)]  = se[i]\n",
    "    return table\n",
    "    \n",
    "\n",
    "table = return_results(['log_enroll'],model_xs,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bc63f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcc|cc}\n",
      "\\toprule\n",
      "{}& \\textbf{coef 1} & \\textbf{se 1}& \\textbf{coef 2} & \\textbf{se 2}\\\\\n",
      "\\midrule\n",
      "\\textbf{ins\\_parent\\_noSNPs} & -0.0170  & 0.0016  & -0.0136  & 0.0016 \\\\\n",
      "\\textbf{star\\_C2} & -0.0004  & 0.0003  & -0.0008  & 0.0003 \\\\\n",
      "\\textbf{bm\\_ns} & nan  & nan  & 0.0002  & 0.0001 \\\\\n",
      "\\textbf{FFS\\_AB} & 0.0004  & 0.0000  & 0.0002  & 0.0000 \\\\\n",
      "\\textbf{unemploy\\_rt} & -0.0131  & 0.0024  & -0.0126  & 0.0024 \\\\\n",
      "\\textbf{pc\\_income} & -0.0087  & 0.0007  & -0.0083  & 0.0007 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & 0.0012  & 0.0010  & 0.0028  & 0.0010 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & 0.0006  & 0.0005  & 0.0003  & 0.0005 \\\\\n",
      "\\textbf{double\\_bonus} & -0.0055  & 0.0099  & nan  & nan \\\\\n",
      "\\textbf{bmFFS\\_ns\\_diff} & -0.0005  & 0.0002  & -0.0008  & 0.0001 \\\\\n",
      "\\textbf{treat*trend} & 1.8067  & 0.1515  & nan  & nan \\\\\n",
      "\\textbf{control*trend} & 1.7378  & 0.1509  & nan  & nan \\\\\n",
      "\\textbf{treat2*trend} & nan  & nan  & 0.0000  & 0.0000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "def table_to_latex(table):\n",
    "    num_col = len(table.columns)\n",
    "    print('\\\\begin{tabular}{l',end='')\n",
    "    for i in range(int(len(table.columns)/2-1)):\n",
    "        print('cc|',end='')\n",
    "    print('cc}')\n",
    "    print('\\\\toprule')\n",
    "    print('{}',end='')\n",
    "    model = 1\n",
    "    while model <= len(table.columns)/2:\n",
    "        print('& \\\\textbf{coef %s} & \\\\textbf{se %s}'%(model,model),end='' )\n",
    "        model = model +1 \n",
    "    print('\\\\\\\\')\n",
    "    print('\\\\midrule')\n",
    "\n",
    "    \n",
    "    for row in table.itertuples():\n",
    "        listrow = list(row)\n",
    "        print('\\\\textbf{%s}'%listrow[0].replace('_','\\\\_'),end='')\n",
    "        for i in range(len(listrow)-1):\n",
    "            print(' & %.4f '%listrow[i+1],end='')\n",
    "        print('\\\\\\\\')\n",
    "    print('\\\\bottomrule')\n",
    "    print('\\\\end{tabular}')\n",
    "    \n",
    "table_to_latex(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9047720e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "['ins_parent_noSNPs', 'star_C2', 'bm_ns', 'FFS_AB', 'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'double_bonus', 'bmFFS_ns_diff', 'treat*trend', 'control*trend', 'treat2*trend']\n",
      "\\begin{center}\n",
      "\\begin{tabular}{ccccc}\n",
      "\\toprule\n",
      "\\textbf{Version} & \\textbf{Result} & \\textbf{90 \\% CI} & \\textbf{95 \\% CI} & \\textbf{99 \\% CI} \\\\ \\midrule\n",
      "Shi (2015) & H0 & [-2.041, 2.452] & [-3.420, 3.831] & [-9.729, 10.140] \\\\\n",
      "Classical & H0 & [-2.287, 1.003] & [-2.601, 1.317] & [-3.218, 1.934] \\\\\n",
      "Bootstrap & H0 & [-1.392, 1.809] & [-1.644, 2.096] & [-2.534, 2.755] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "None\n",
      "[[('ll1', 'll2'), -0.6420596816041239, 85, 85, 85]]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import selection_tests\n",
    "\n",
    "\n",
    "class GLS_LL(GenericLikelihoodModel):\n",
    "\n",
    "    def __init__(self, *args, model=None, **kwargs):\n",
    "        super(GLS_LL, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def loglikeobs(self, params, scale=None):\n",
    "        \"\"\"\n",
    "        Evaluate the log-likelihood for a generalized linear model.\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        scale = sm.tsa.stattools.float_like(scale, \"scale\", optional=True)\n",
    "        lin_pred = np.dot(model.exog, params) + model._offset_exposure\n",
    "        expval = model.family.link.inverse(lin_pred)\n",
    "        if scale is None:\n",
    "            scale = model.estimate_scale(expval)\n",
    "        llf = model.family.loglike_obs(model.endog, expval, model.var_weights,\n",
    "                                  scale)\n",
    "        return llf\n",
    "\n",
    "\n",
    "\n",
    "#this is janky as f.... need to fix it...\n",
    "def setup_test(y_dot,X_dot,\n",
    "    model1_cov = [],\n",
    "    model2_cov = []):\n",
    "    \n",
    "    #model 1\n",
    "    #weights = np.array( data['enr_c_mean'][missing_vals] )\n",
    "    m1 = sm.GLM(y_dot,X_dot[model1_cov])#,var_weights=weights)\n",
    "    m1_fit = m1.fit()\n",
    "\n",
    "    #model2\n",
    "    m2 = sm.GLM(y_dot,X_dot[model2_cov])#,var_weights=weights)\n",
    "    m2_fit = m2.fit()\n",
    "\n",
    "    model1 = GLS_LL(y_dot, X_dot[model1_cov], model=m1)\n",
    "    ll1 = model1.loglikeobs(m1_fit.params)\n",
    "    grad1 = model1.score_obs(m1_fit.params)\n",
    "    hess1 = model1.hessian(m1_fit.params)\n",
    "    params1 = m1_fit.params\n",
    "\n",
    "    model2 = GLS_LL(y_dot, X_dot[model2_cov], model=m2)\n",
    "\n",
    "    ll2 = model2.loglikeobs(m2_fit.params)\n",
    "    grad2 = model2.score_obs(m2_fit.params)\n",
    "    hess2 = model2.hessian(m2_fit.params)\n",
    "    params2 = m2_fit.params\n",
    "    \n",
    "    return  ll1, grad1, hess1, params1, ll2, grad2, hess2, params2\n",
    "\n",
    "\n",
    "\n",
    "def pairwise_tests(y_name,model_xs,data):\n",
    "    y_dot,X_dot,x_name,missing_vals = setup_data(y_name,model_xs,data)\n",
    "    \n",
    "    \n",
    "    #TODO fix this so that it does all the comparison\n",
    "    combos = list(itertools.combinations(model_xs,2))\n",
    "    labels = [ 'll'+ str(i+1) for i in range(len(model_xs))]\n",
    "    label_combos = list(itertools.combinations(labels,2))\n",
    "    res = []\n",
    "    for i in range(len(combos)):\n",
    "        combo = combos[i]\n",
    "        label_combo = label_combos[i]\n",
    "        model1_x = combo[0]\n",
    "        model2_x = combo[1]\n",
    "        setup_test_i = lambda yn,xn : setup_test(yn,xn,model1_cov = model1_x, model2_cov= model2_x)\n",
    "        test_stat,res1,res2,res3 = selection_tests.test_results(y_dot,X_dot,setup_test_i)\n",
    "        \n",
    "        print(selection_tests.test_table(y_dot,X_dot,setup_test_i))\n",
    "        \n",
    "        res.append( [label_combo,test_stat,res1,res2,res3])\n",
    "    #print_pairwise_tests(res)\n",
    "    return res\n",
    "\n",
    "\n",
    "res = pairwise_tests(['log_enroll'],model_xs,data)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23318b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e69da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a7e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
