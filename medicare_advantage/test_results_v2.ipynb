{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88999733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "#graphing\n",
    "import matplotlib.pyplot as plt\n",
    "#stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from sklearn.mixture import GaussianMixture \n",
    "#import testing\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import selection_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafc4a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ssa', 'state', 'county', 'year', 'enr_FFS', 'enr_c', 'hhi_ins',\n",
      "       'hhi_ins_noSNP', 'ins_parent', 'ins_parent_noSNPs', 'ins_plans',\n",
      "       'HMO_share', 'PPO_share', 'qual_2012', 'qual_2013', 'qual_2014',\n",
      "       'qual_2015', 'partaenrollment', 'partb_enrollment',\n",
      "       'prescription_drugs', 'prev_comp_dental', 'eye_exams', 'hearing_exams',\n",
      "       'deductible', 'partb_premium', 'plan_premium', 'partd_premium', 'OOPC',\n",
      "       'risk_pub_p', 'bid_pub_p', 'rebate_pub_p', 'risk_pub_c', 'bid_pub_c',\n",
      "       'rebate_pub_c', 'star_C2', 'star_CD2', 'bmFFS', 'bm_ns', 'risk_FFS',\n",
      "       'FFS_AB', 'FFS_AB_rs', 'buydown', 'OOPC_noprem', 'extras', 'quartile',\n",
      "       'bid_pub_p_nominal', 'bid_pub_c_nominal', 'rebate_pub_p_nominal',\n",
      "       'rebate_pub_c_nominal', 'bmFFS_nominal', 'FFS_AB_nominal',\n",
      "       'bm_ns_nominal', 'OOPC_nominal', 'plan_premium_nominal',\n",
      "       'partd_premium_nominal', 'buydown_nominal', 'rebate_std',\n",
      "       'benchmark_diff', 'benchmark_diff_n', 'benchmark_diff_ns', 'quart_yr',\n",
      "       'quart2', 'total_premium', 'rural_urban', 'unemploy_rt', 'pc_income',\n",
      "       'partD', 'enr_c_mean', 'st', 'post', 'post_bmFFS', 'risk_pub_c_std',\n",
      "       'risk_pub_p_std', 'risk_FFS_std', 'log_risk_FFS', 'log_risk_pub_c',\n",
      "       'log_risk_pub_p', 'count', 'log_enroll', 'enr_total'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_stata(\"all_plans_c.dta\")\n",
    "data['log_enroll'] = np.log(data['enr_c'])\n",
    "data['enr_total'] = data['enr_c'] + data['enr_FFS']\n",
    "data = data[data['year'] > 2011]\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4d2936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statsmodels.org/dev/examples/notebooks/generated/glm_weights.html\n",
    "\n",
    "def drop_data(data,y_name,x_name,absorb=None):\n",
    "    data = data.copy()\n",
    "    data = data[y_name + x_name + absorb]\n",
    "    missing_vals = ~data.isnull().max(axis=1)\n",
    "    data = data[missing_vals]\n",
    "    data = data[data['year'].groupby(data['ssa']).transform('count')>=11]\n",
    "    return data\n",
    "    \n",
    "\n",
    "def demean(y_name,x_name,data=None,absorb=None,cluster=None): \n",
    "\n",
    "    y,X = data[ y_name], data[ x_name ]\n",
    "    \n",
    "    y_dot = y.copy()\n",
    "    X_dot = X.copy()\n",
    "    \n",
    "    ybar = y.mean()\n",
    "    Xbar = X.mean()\n",
    "\n",
    "    \n",
    "    for effect in absorb:\n",
    "        y_dot = y_dot - y.groupby(data[effect]).transform('mean')\n",
    "        X_dot = X_dot - X.groupby(data[effect]).transform('mean') \n",
    "    \n",
    "    y_dot = y_dot + ybar\n",
    "    X_dot = X_dot + Xbar\n",
    "    return y_dot, X_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00861d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2502170408036711\n",
      "bmFFS                806.836243\n",
      "log_risk_pub_c        -6.476725\n",
      "FFS_AB               697.544678\n",
      "ins_parent_noSNPs      2.891324\n",
      "unemploy_rt            6.205707\n",
      "pc_income             39.985490\n",
      "rebate_pub_c          45.108919\n",
      "risk_pub_c             0.943594\n",
      "dtype: float64\n",
      "bmFFS                804.860901\n",
      "log_risk_pub_c        -8.548820\n",
      "FFS_AB               721.982910\n",
      "ins_parent_noSNPs      1.786617\n",
      "unemploy_rt            6.563941\n",
      "pc_income             38.069699\n",
      "rebate_pub_c          30.189500\n",
      "risk_pub_c             0.930363\n",
      "dtype: float64\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}      &   log\\_enroll    & \\textbf{  No. Observations:  } &    16126    \\\\\n",
      "\\textbf{Model:}              &       GLM        & \\textbf{  Df Residuals:      } &    16119    \\\\\n",
      "\\textbf{Model Family:}       &     Gaussian     & \\textbf{  Df Model:          } &        6    \\\\\n",
      "\\textbf{Link Function:}      &     identity     & \\textbf{  Scale:             } &    46.290   \\\\\n",
      "\\textbf{Method:}             &       IRLS       & \\textbf{  Log-Likelihood:    } &   -2725.5   \\\\\n",
      "\\textbf{Date:}               & Thu, 15 Dec 2022 & \\textbf{  Deviance:          } & 7.4615e+05  \\\\\n",
      "\\textbf{Time:}               &     18:20:50     & \\textbf{  Pearson chi2:      } &  7.46e+05   \\\\\n",
      "\\textbf{No. Iterations:}     &        3         & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{bmFFS}               &       0.0005  &     3.54e-05     &    15.302  &         0.000        &        0.000    &        0.001     \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c}   &       0.0032  &        0.000     &    10.051  &         0.000        &        0.003    &        0.004     \\\\\n",
      "\\textbf{FFS\\_AB}             &   -6.741e-05  &     4.28e-05     &    -1.576  &         0.115        &       -0.000    &     1.64e-05     \\\\\n",
      "\\textbf{ins\\_parent\\_noSNPs} &       0.0150  &        0.001     &    11.966  &         0.000        &        0.013    &        0.017     \\\\\n",
      "\\textbf{unemploy\\_rt}        &      -0.0123  &        0.002     &    -7.944  &         0.000        &       -0.015    &       -0.009     \\\\\n",
      "\\textbf{pc\\_income}          &      -0.0060  &        0.000     &   -12.933  &         0.000        &       -0.007    &       -0.005     \\\\\n",
      "\\textbf{rebate\\_pub\\_c}      &       0.0004  &     9.16e-05     &     4.216  &         0.000        &        0.000    &        0.001     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n",
      "\\begin{center}\n",
      "\\begin{tabular}{lclc}\n",
      "\\toprule\n",
      "\\textbf{Dep. Variable:}      &   log\\_enroll    & \\textbf{  No. Observations:  } &    16126    \\\\\n",
      "\\textbf{Model:}              &       GLM        & \\textbf{  Df Residuals:      } &    16118    \\\\\n",
      "\\textbf{Model Family:}       &     Gaussian     & \\textbf{  Df Model:          } &        7    \\\\\n",
      "\\textbf{Link Function:}      &     identity     & \\textbf{  Scale:             } &    46.204   \\\\\n",
      "\\textbf{Method:}             &       IRLS       & \\textbf{  Log-Likelihood:    } &   -2710.0   \\\\\n",
      "\\textbf{Date:}               & Thu, 15 Dec 2022 & \\textbf{  Deviance:          } & 7.4472e+05  \\\\\n",
      "\\textbf{Time:}               &     18:20:50     & \\textbf{  Pearson chi2:      } &  7.45e+05   \\\\\n",
      "\\textbf{No. Iterations:}     &        3         & \\textbf{                     } &             \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\begin{tabular}{lcccccc}\n",
      "                             & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{bmFFS}               &       0.0005  &     3.59e-05     &    14.129  &         0.000        &        0.000    &        0.001     \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c}   &       0.0031  &        0.000     &     9.752  &         0.000        &        0.002    &        0.004     \\\\\n",
      "\\textbf{FFS\\_AB}             &   -6.122e-05  &     4.28e-05     &    -1.432  &         0.152        &       -0.000    &     2.26e-05     \\\\\n",
      "\\textbf{ins\\_parent\\_noSNPs} &       0.0152  &        0.001     &    12.128  &         0.000        &        0.013    &        0.018     \\\\\n",
      "\\textbf{unemploy\\_rt}        &      -0.0123  &        0.002     &    -7.937  &         0.000        &       -0.015    &       -0.009     \\\\\n",
      "\\textbf{pc\\_income}          &      -0.0061  &        0.000     &   -13.108  &         0.000        &       -0.007    &       -0.005     \\\\\n",
      "\\textbf{rebate\\_pub\\_c}      &       0.0004  &     9.16e-05     &     4.289  &         0.000        &        0.000    &        0.001     \\\\\n",
      "\\textbf{bmFFS*c}             &       0.0007  &        0.000     &     5.563  &         0.000        &        0.000    &        0.001     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "%\\caption{Generalized Linear Model Regression Results}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "class GLS_LL(GenericLikelihoodModel):\n",
    "\n",
    "    def __init__(self, *args, model=None, **kwargs):\n",
    "        super(GLS_LL, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def loglikeobs(self, params, scale=None):\n",
    "        \"\"\"\n",
    "        Evaluate the log-likelihood for a generalized linear model.\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        scale = sm.tsa.stattools.float_like(scale, \"scale\", optional=True)\n",
    "        lin_pred = np.dot(model.exog, params) + model._offset_exposure\n",
    "        expval = model.family.link.inverse(lin_pred)\n",
    "        if scale is None:\n",
    "            scale = model.estimate_scale(expval)\n",
    "        llf = model.family.loglike_obs(model.endog, expval, model.var_weights,\n",
    "                                  scale)\n",
    "        return llf\n",
    "\n",
    "    \n",
    "def print_results(y_name,data,weights=True):\n",
    "    \n",
    "    x_name = ['bmFFS', 'log_risk_pub_c','FFS_AB',\"ins_parent_noSNPs\",'unemploy_rt',\n",
    "              'pc_income','rebate_pub_c']\n",
    "    #'post_bmFFS',\n",
    "    y_dot, X_dot = demean(y_name,x_name, data=data,absorb=['ssa','year'])\n",
    "    missing_vals = ~data[y_name + x_name].isnull().max(axis=1)\n",
    "    y_dot, X_dot = y_dot[missing_vals],X_dot[missing_vals]\n",
    "    gmmodel = GaussianMixture (n_components=2)\n",
    "\n",
    "    #model 1 set up data\n",
    "    data_stack = X_dot[['log_risk_pub_c']].copy()\n",
    "    data_stack['y'] = y_dot\n",
    "    classify = GaussianMixture (n_components=2).fit(data_stack)\n",
    "    c = np.array(classify.predict(data_stack))\n",
    "\n",
    "    classify = gmmodel.fit(data_stack)\n",
    "    c = np.array(classify.predict(data_stack))\n",
    "    \n",
    "    print(c.sum()/c.shape[0] )\n",
    "    print(data[missing_vals][x_name+['risk_pub_c']][c==0].mean() )\n",
    "    print(data[missing_vals][x_name+['risk_pub_c']][c==1].mean() )\n",
    "    \n",
    "    #model 2 set up data\n",
    "    X_dot2 = X_dot.copy()\n",
    "    X_dot2['bmFFS*c'] = X_dot['bmFFS']*c\n",
    "    \n",
    "\n",
    "    m1,m2 = None,None\n",
    "    if weights:\n",
    "        weights = np.array( data['enr_c'][missing_vals] )\n",
    "        m1 = sm.GLM(y_dot,X_dot,var_weights=weights)\n",
    "        m2 = sm.GLM(y_dot,X_dot2,var_weights=weights)\n",
    "    else:\n",
    "        m1 = sm.GLM(y_dot,X_dot)\n",
    "        m2 = sm.GLM(y_dot,X_dot2)\n",
    "        \n",
    "    #model 1\n",
    "    m1_fit = m1.fit()\n",
    "    print(m1_fit.summary().as_latex())\n",
    "    m2_fit = m2.fit()\n",
    "    print(m2_fit.summary().as_latex())\n",
    "    \n",
    "print_results(['log_enroll'],data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9047720e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{ccccc}\n",
      "\\toprule\n",
      "\\textbf{Version} & \\textbf{Result} & \\textbf{90 \\% CI} & \\textbf{95 \\% CI} & \\textbf{99 \\% CI} \\\\ \\midrule\n",
      "Shi (2015) & H0 & [-6.200, 2.179] & [-9.510, 5.494] & [-15.911, 11.890] \\\\\n",
      "Classical & H2 & [-3.782, -0.492] & [-4.096, -0.178] & [-4.713, 0.439] \\\\\n",
      "Bootstrap & H0 & [-3.788, -0.298] & [-4.219, 0.066] & [-4.829, 0.571] \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#this is janky as f.... need to fix it...\n",
    "def setup_test(yn, xn,\n",
    "    y_name = ['log_enroll'],\n",
    "    x_name = ['bmFFS','log_risk_pub_c','FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']):\n",
    "    \n",
    "    data = xn.copy()\n",
    "\n",
    "    #data1 = drop_data(data,y_name,x_name,absorb=['ssa','year'])\n",
    "    y_dot, X_dot = demean(y_name,x_name, data=data,absorb=['ssa','year'])\n",
    "    missing_vals = ~data[y_name + x_name].isnull().max(axis=1)\n",
    "    y_dot, X_dot = y_dot[missing_vals],X_dot[missing_vals]\n",
    "\n",
    "    #double check if weighting + claissifer helps\n",
    "    gmmodel = GaussianMixture (n_components=2)\n",
    "\n",
    "    #high risk score, low enrollment? much bigger benchmark effect...\n",
    "    data_stack = X_dot[['log_risk_pub_c']].copy()\n",
    "    data_stack['y'] = y_dot\n",
    "    classify = GaussianMixture (n_components=2).fit(data_stack)\n",
    "    c = np.array(classify.predict(data_stack))\n",
    "\n",
    "    classify = gmmodel.fit(data_stack)\n",
    "    c = np.array(classify.predict(data_stack))\n",
    "\n",
    "    #model 1\n",
    "    weights = np.array( data['enr_c_mean'][missing_vals] )\n",
    "    m1 = sm.GLM(y_dot,X_dot)#,var_weights=weights)\n",
    "    m1_fit = m1.fit()\n",
    "    \n",
    "\n",
    "    #model2\n",
    "    X_dot2 = X_dot.copy()\n",
    "    X_dot2['bmFFS*c'] = X_dot['bmFFS']*c\n",
    "    m2 = sm.GLM(y_dot,X_dot2)#,var_weights=weights)\n",
    "    m2_fit = m2.fit()\n",
    "\n",
    "    model1 = GLS_LL(y_dot, X_dot, model=m1)\n",
    "    ll1 = model1.loglikeobs(m1_fit.params)\n",
    "    grad1 = model1.score_obs(m1_fit.params)\n",
    "    hess1 = model1.hessian(m1_fit.params)\n",
    "    params1 = m1_fit.params\n",
    "\n",
    "    # fit logistic values\n",
    "    model2 = GLS_LL(y_dot, X_dot, model=m2)\n",
    "    ll2 = model2.loglikeobs(m2_fit.params)\n",
    "    grad2 = model2.score_obs(m2_fit.params)\n",
    "    hess2 = model2.hessian(m2_fit.params)\n",
    "    params2 = m2_fit.params\n",
    "\n",
    "    return  ll1, grad1, hess1, params1, ll2, grad2, hess2, params2\n",
    "\n",
    "\n",
    "print(selection_tests.test_table(data['log_enroll'],data,setup_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e28f747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e69da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
