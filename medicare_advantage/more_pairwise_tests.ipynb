{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88999733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "#graphing\n",
    "import matplotlib.pyplot as plt\n",
    "#stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.base.model import GenericLikelihoodModel\n",
    "from sklearn.mixture import GaussianMixture \n",
    "#import testing\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import selection_tests\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafc4a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'ssa', 'state', 'county', 'year', 'enr_FFS', 'enr_c',\n",
      "       'hhi_ins', 'hhi_ins_noSNP', 'ins_parent', 'ins_parent_noSNPs',\n",
      "       'ins_plans', 'HMO_share', 'PPO_share', 'qual_2012', 'qual_2013',\n",
      "       'qual_2014', 'qual_2015', 'partaenrollment', 'partb_enrollment',\n",
      "       'prescription_drugs', 'prev_comp_dental', 'eye_exams', 'hearing_exams',\n",
      "       'deductible', 'partb_premium', 'plan_premium', 'partd_premium', 'OOPC',\n",
      "       'risk_pub_p', 'bid_pub_p', 'rebate_pub_p', 'risk_pub_c', 'bid_pub_c',\n",
      "       'rebate_pub_c', 'star_C2', 'star_CD2', 'bmFFS', 'bm_ns', 'risk_FFS',\n",
      "       'FFS_AB', 'FFS_AB_rs', 'buydown', 'OOPC_noprem', 'extras', 'quartile',\n",
      "       'bid_pub_p_nominal', 'bid_pub_c_nominal', 'rebate_pub_p_nominal',\n",
      "       'rebate_pub_c_nominal', 'bmFFS_nominal', 'FFS_AB_nominal',\n",
      "       'bm_ns_nominal', 'OOPC_nominal', 'plan_premium_nominal',\n",
      "       'partd_premium_nominal', 'buydown_nominal', 'rebate_std',\n",
      "       'benchmark_diff', 'benchmark_diff_n', 'benchmark_diff_ns', 'quart_yr',\n",
      "       'quart2', 'total_premium', 'rural_urban', 'unemploy_rt', 'pc_income',\n",
      "       'partD', 'enr_c_mean', 'st', 'post', 'post_bmFFS', 'risk_pub_c_std',\n",
      "       'risk_pub_p_std', 'risk_FFS_std', 'log_risk_FFS', 'log_risk_pub_c',\n",
      "       'log_risk_pub_p', 'count', 'double_bonus', 'log_enroll', 'enr_total'],\n",
      "      dtype='object')\n",
      "832.3834838867188\n",
      "806.34423828125\n",
      "7.60477352142334\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_stata(\"all_plans_c_bonus.dta\")\n",
    "data['log_enroll'] = np.log(data['enr_c'])\n",
    "data['enr_total'] = data['enr_c'] + data['enr_FFS']\n",
    "data = data[data['year'] > 2011]\n",
    "print(data.columns)\n",
    "\n",
    "print(data[data['double_bonus']==1]['bmFFS'].mean())\n",
    "print(data['bmFFS'].mean())\n",
    "print(data['star_C2'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14255a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textbf{double\\_bonus} & 0.0687  & 0.2530 \\\\\n",
      "\\textbf{bmFFS} & 806.3442  & 59.9781 \\\\\n",
      "\\textbf{ins\\_parent\\_noSNPs} & 2.6149  & 1.5398 \\\\\n",
      "\\textbf{FFS\\_AB} & 703.6609  & 95.1605 \\\\\n",
      "\\textbf{unemploy\\_rt} & 6.2953  & 2.4442 \\\\\n",
      "\\textbf{pc\\_income} & 39.5061  & 10.7500 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & -3.8737  & 7.5688 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & -6.9952  & 12.9910 \\\\\n",
      "\\textbf{risk\\_pub\\_c} & 0.9403  & 0.1217 \\\\\n",
      "\\textbf{rebate\\_pub\\_c} & 41.3758  & 32.7914 \\\\\n"
     ]
    }
   ],
   "source": [
    "def join_print(t1,t2,\n",
    "               summary_xs=['double_bonus', 'bmFFS',  'ins_parent_noSNPs',  'FFS_AB', \n",
    "                           'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', \n",
    "                           'risk_pub_c', 'rebate_pub_c'] ):\n",
    "    table =  pd.DataFrame(index=summary_xs)\n",
    "    table['1'] = t1\n",
    "    table['2'] = t2\n",
    "    \n",
    "    for row in table.itertuples():\n",
    "        listrow = list(row)\n",
    "        print('\\\\textbf{%s}'%listrow[0].replace('_','\\\\_'),end='')\n",
    "        for i in range(len(listrow)-1):\n",
    "            print(' & %.4f '%listrow[i+1],end='')\n",
    "        print('\\\\\\\\')\n",
    "\n",
    "summary_xs1=['double_bonus', 'bmFFS', 'bm_ns','star_C2', 'ins_parent_noSNPs',  'FFS_AB', \n",
    "                           'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', \n",
    "                           'risk_pub_c', 'rebate_pub_c']\n",
    "\n",
    "join_print(data[summary_xs1].mean(),data[summary_xs1].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d2936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statsmodels.org/dev/examples/notebooks/generated/glm_weights.html\n",
    "\n",
    "def drop_data(data,y_name,x_name,absorb=None):\n",
    "    data = data.copy()\n",
    "    data = data[y_name + x_name + absorb]\n",
    "    missing_vals = ~data.isnull().max(axis=1)\n",
    "    data = data[missing_vals]\n",
    "    data = data[data['year'].groupby(data['ssa']).transform('count')>=11]\n",
    "    return data\n",
    "    \n",
    "\n",
    "def demean(y_name,x_name,data=None,absorb=None,cluster=None): \n",
    "\n",
    "    y,X = data[ y_name], data[ x_name ]\n",
    "    \n",
    "    y_dot = y.copy()\n",
    "    X_dot = X.copy()\n",
    "    \n",
    "    ybar = y.mean()\n",
    "    Xbar = X.mean()\n",
    "\n",
    "    \n",
    "    for effect in absorb:\n",
    "        y_dot = y_dot - y.groupby(data[effect]).transform('mean')\n",
    "        X_dot = X_dot - X.groupby(data[effect]).transform('mean') \n",
    "    \n",
    "    y_dot = y_dot + ybar\n",
    "    X_dot = X_dot + Xbar\n",
    "    return y_dot, X_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00861d9c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ins_parent_noSNPs', 'star_C2', 'bmFFS', 'bm_ns', 'FFS_AB', 'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'double_bonus']\n",
      "0.744511968250031\n",
      "\\textbf{double\\_bonus} & 0.0036  & 0.0910 \\\\\n",
      "\\textbf{bmFFS} & 804.7476  & 806.8893 \\\\\n",
      "\\textbf{ins\\_parent\\_noSNPs} & 1.7920  & 2.8973 \\\\\n",
      "\\textbf{FFS\\_AB} & 721.2720  & 697.6155 \\\\\n",
      "\\textbf{unemploy\\_rt} & 6.5507  & 6.2077 \\\\\n",
      "\\textbf{pc\\_income} & 38.1133  & 39.9841 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & -4.4944  & -3.6608 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & -8.5549  & -6.4600 \\\\\n",
      "\\textbf{risk\\_pub\\_c} & 0.9302  & 0.9437 \\\\\n",
      "\\textbf{rebate\\_pub\\_c} & 30.2175  & 45.2049 \\\\\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "model1_x = ['double_bonus','log_risk_pub_c', 'bm_ns','star_C2',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']\n",
    "\n",
    "model2_x = ['bmFFS','log_risk_pub_c', 'bm_ns','star_C2',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income']\n",
    "    \n",
    "model3_x = ['bmFFS', 'log_risk_pub_c', 'bm_ns','star_C2',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income','bmFFS*log_risk_pub_c']\n",
    "\n",
    "\n",
    "model4_x = ['bmFFS',  'log_risk_pub_c', 'bm_ns','star_C2',\n",
    "            'FFS_AB',\"ins_parent_noSNPs\",'log_risk_FFS','unemploy_rt','pc_income','bmFFS*c']\n",
    "\n",
    "model_xs = [model1_x,model2_x,model3_x,model4_x]\n",
    "\n",
    "\n",
    "\n",
    "def create_latent(y_dot, X_dot, missing_vals):\n",
    "    gmmodel = GaussianMixture (n_components=2)\n",
    "    \n",
    "    #setup data\n",
    "    data_stack = X_dot[['log_risk_pub_c']].copy()\n",
    "    data_stack['y'] = y_dot\n",
    "    \n",
    "    #predict\n",
    "    classify = GaussianMixture (n_components=2).fit(data_stack)\n",
    "    c = np.array(classify.predict(data_stack))\n",
    "    return c\n",
    "    \n",
    "    \n",
    "def latent_stats(c,data,x_name,missing_vals):\n",
    "    summary_xs=['double_bonus', 'bmFFS',  'ins_parent_noSNPs',  'FFS_AB', 'bm_ns','star_C2', \n",
    "                           'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', \n",
    "                           'risk_pub_c', 'rebate_pub_c'] \n",
    "    print(c.sum()/c.shape[0] )\n",
    "    join_print(data[missing_vals][summary_xs][c==0].mean() ,data[missing_vals][summary_xs][c==1].mean()  )\n",
    "\n",
    "\n",
    "def setup_data(y_name,model_xs,data):\n",
    "     #get the super set of all the model names\n",
    "    all_xs = set()\n",
    "    for model_x in model_xs:\n",
    "        all_xs = all_xs.union(set(model_x))\n",
    "    all_xs = list(all_xs)\n",
    "    \n",
    "    #subtract out the columns that are not in the data\n",
    "    x_name = []\n",
    "    for col in data.columns:\n",
    "        if col in all_xs:\n",
    "            x_name.append(col)\n",
    "    print(x_name)\n",
    "    \n",
    "    #clean the data\n",
    "    y_dot, X_dot = demean(y_name,x_name, data=data,absorb=['ssa','year'])\n",
    "    missing_vals = ~data[y_name + x_name].isnull().max(axis=1)\n",
    "    y_dot, X_dot = y_dot[missing_vals],X_dot[missing_vals]\n",
    "    return y_dot,X_dot,x_name,missing_vals\n",
    "\n",
    "\n",
    "\n",
    "def return_results(y_name,model_xs,data,weights=True):\n",
    "    y_dot,X_dot,x_name,missing_vals = setup_data(y_name,model_xs,data)\n",
    "    \n",
    "    #setup the latent variable\n",
    "    c =  create_latent(y_dot, X_dot, missing_vals)\n",
    "    latent_stats(c,data,x_name,missing_vals)\n",
    "    \n",
    "    #setup interactions\n",
    "    X_dot['bmFFS*c'] = X_dot['bmFFS']*c\n",
    "    X_dot['bmFFS*log_risk_pub_c'] = X_dot['bmFFS']*X_dot['log_risk_pub_c']\n",
    "    \n",
    "    print('-----')\n",
    "    params = []\n",
    "    se = []\n",
    "    for model_x in model_xs:\n",
    "        if weights:\n",
    "            var_weights = np.array( data['enr_c'][missing_vals] )\n",
    "            X_dot_m = X_dot[model_x].copy()\n",
    "            model = sm.GLM(y_dot,X_dot_m,var_weights=var_weights)\n",
    "            model_fit = model.fit()\n",
    "            params.append(model_fit.params)\n",
    "            se.append(model_fit.bse)\n",
    "    table  = pd.DataFrame(index=x_name + ['bmFFS*c','bmFFS*log_risk_pub_c'])\n",
    "    col_names = []\n",
    "    for i in range(len(model_xs)):\n",
    "        table['params %i'%(i+1)]  = params[i]\n",
    "        table['se %i'%(i+1)]  = se[i]\n",
    "    return table\n",
    "    \n",
    "\n",
    "table = return_results(['log_enroll'],model_xs,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc63f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lcc|cc|cc|cc}\n",
      "\\toprule\n",
      "{}& \\textbf{coef 1} & \\textbf{se 1}& \\textbf{coef 2} & \\textbf{se 2}& \\textbf{coef 3} & \\textbf{se 3}& \\textbf{coef 4} & \\textbf{se 4}\\\\\n",
      "\\midrule\n",
      "\\textbf{ins\\_parent\\_noSNPs} & 0.0166  & 0.0013  & 0.0159  & 0.0013  & 0.0161  & 0.0013  & 0.0161  & 0.0013 \\\\\n",
      "\\textbf{star\\_C2} & -0.0014  & 0.0002  & -0.0014  & 0.0002  & -0.0014  & 0.0002  & -0.0014  & 0.0002 \\\\\n",
      "\\textbf{bmFFS} & nan  & nan  & 0.0002  & 0.0001  & 0.0001  & 0.0001  & 0.0009  & 0.0002 \\\\\n",
      "\\textbf{bm\\_ns} & 0.0006  & 0.0000  & 0.0005  & 0.0001  & 0.0005  & 0.0001  & 0.0005  & 0.0001 \\\\\n",
      "\\textbf{FFS\\_AB} & -0.0001  & 0.0000  & -0.0001  & 0.0000  & -0.0001  & 0.0000  & -0.0001  & 0.0000 \\\\\n",
      "\\textbf{unemploy\\_rt} & -0.0112  & 0.0015  & -0.0116  & 0.0016  & -0.0119  & 0.0016  & -0.0116  & 0.0016 \\\\\n",
      "\\textbf{pc\\_income} & -0.0045  & 0.0005  & -0.0051  & 0.0005  & -0.0052  & 0.0005  & -0.0052  & 0.0005 \\\\\n",
      "\\textbf{log\\_risk\\_FFS} & 0.0027  & 0.0007  & 0.0030  & 0.0007  & 0.0032  & 0.0007  & 0.0030  & 0.0007 \\\\\n",
      "\\textbf{log\\_risk\\_pub\\_c} & 0.0023  & 0.0003  & 0.0025  & 0.0003  & 0.0025  & 0.0003  & 0.0024  & 0.0003 \\\\\n",
      "\\textbf{double\\_bonus} & 0.0305  & 0.0040  & nan  & nan  & nan  & nan  & nan  & nan \\\\\n",
      "\\textbf{bmFFS*c} & nan  & nan  & nan  & nan  & nan  & nan  & -0.0008  & 0.0001 \\\\\n",
      "\\textbf{bmFFS*log\\_risk\\_pub\\_c} & nan  & nan  & nan  & nan  & 0.0000  & 0.0000  & nan  & nan \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "def table_to_latex(table):\n",
    "    num_col = len(table.columns)\n",
    "    print('\\\\begin{tabular}{l',end='')\n",
    "    for i in range(int(len(table.columns)/2-1)):\n",
    "        print('cc|',end='')\n",
    "    print('cc}')\n",
    "    print('\\\\toprule')\n",
    "    print('{}',end='')\n",
    "    model = 1\n",
    "    while model <= len(table.columns)/2:\n",
    "        print('& \\\\textbf{coef %s} & \\\\textbf{se %s}'%(model,model),end='' )\n",
    "        model = model +1 \n",
    "    print('\\\\\\\\')\n",
    "    print('\\\\midrule')\n",
    "\n",
    "    \n",
    "    for row in table.itertuples():\n",
    "        listrow = list(row)\n",
    "        print('\\\\textbf{%s}'%listrow[0].replace('_','\\\\_'),end='')\n",
    "        for i in range(len(listrow)-1):\n",
    "            print(' & %.4f '%listrow[i+1],end='')\n",
    "        print('\\\\\\\\')\n",
    "    print('\\\\bottomrule')\n",
    "    print('\\\\end{tabular}')\n",
    "    \n",
    "table_to_latex(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9047720e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ins_parent_noSNPs', 'star_C2', 'bmFFS', 'bm_ns', 'FFS_AB', 'unemploy_rt', 'pc_income', 'log_risk_FFS', 'log_risk_pub_c', 'double_bonus']\n",
      "('ll1', 'll2') -2.0965416567514286 95 90 90\n",
      "('ll1', 'll3') -2.111732553866967 95 85 90\n",
      "('ll1', 'll4') -3.4418968932339156 99 90 99\n",
      "('ll2', 'll3') -0.09146312303085556 85 90 99\n",
      "('ll2', 'll4') -2.142668790625963 95 85 90\n",
      "('ll3', 'll4') -2.1537105767995697 95 90 95\n"
     ]
    }
   ],
   "source": [
    "class GLS_LL(GenericLikelihoodModel):\n",
    "\n",
    "    def __init__(self, *args, model=None, **kwargs):\n",
    "        super(GLS_LL, self).__init__(*args, **kwargs)\n",
    "        self.model = model\n",
    "        \n",
    "    def loglikeobs(self, params, scale=None):\n",
    "        \"\"\"\n",
    "        Evaluate the log-likelihood for a generalized linear model.\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        scale = sm.tsa.stattools.float_like(scale, \"scale\", optional=True)\n",
    "        lin_pred = np.dot(model.exog, params) + model._offset_exposure\n",
    "        expval = model.family.link.inverse(lin_pred)\n",
    "        if scale is None:\n",
    "            scale = model.estimate_scale(expval)\n",
    "        llf = model.family.loglike_obs(model.endog, expval, model.var_weights,\n",
    "                                  scale)\n",
    "        return llf\n",
    "\n",
    "\n",
    "\n",
    "#this is janky as f.... need to fix it...\n",
    "#this is janky as f.... need to fix it...\n",
    "def setup_test(y_dot,X_dot,\n",
    "    model1_cov = [],\n",
    "    model2_cov = []):\n",
    "    \n",
    "    #model 1\n",
    "    #weights = np.array( data['enr_c_mean'][missing_vals] )\n",
    "    m1 = sm.GLM(y_dot,X_dot[model1_cov])#,var_weights=weights)\n",
    "    m1_fit = m1.fit()\n",
    "\n",
    "    #model2\n",
    "    m2 = sm.GLM(y_dot,X_dot[model2_cov])#,var_weights=weights)\n",
    "    m2_fit = m2.fit()\n",
    "\n",
    "    model1 = GLS_LL(y_dot, X_dot[model1_cov], model=m1)\n",
    "    ll1 = model1.loglikeobs(m1_fit.params)\n",
    "    grad1 = model1.score_obs(m1_fit.params)\n",
    "    hess1 = model1.hessian(m1_fit.params)\n",
    "    params1 = m1_fit.params\n",
    "\n",
    "    model2 = GLS_LL(y_dot, X_dot[model2_cov], model=m2)\n",
    "\n",
    "    ll2 = model2.loglikeobs(m2_fit.params)\n",
    "    grad2 = model2.score_obs(m2_fit.params)\n",
    "    hess2 = model2.hessian(m2_fit.params)\n",
    "    params2 = m2_fit.params\n",
    "    \n",
    "    return  ll1, grad1, hess1, params1, ll2, grad2, hess2, params2\n",
    "\n",
    "\n",
    "\n",
    "def pairwise_tests(y_name,model_xs,data):\n",
    "    y_dot,X_dot,x_name,missing_vals = setup_data(y_name,model_xs,data)\n",
    "    \n",
    "    #setup the latent variable\n",
    "    c =  create_latent(y_dot, X_dot, missing_vals)\n",
    "    \n",
    "    #setup interactions\n",
    "    X_dot['bmFFS*c'] = X_dot['bmFFS']*c\n",
    "    X_dot['bmFFS*log_risk_pub_c'] = X_dot['bmFFS']*X_dot['log_risk_pub_c']\n",
    "    \n",
    "    #TODO fix this so that it does all the comparison\n",
    "    combos = list(itertools.combinations(model_xs,2))\n",
    "    labels = [ 'll'+ str(i+1) for i in range(len(model_xs))]\n",
    "    label_combos = list(itertools.combinations(labels,2))\n",
    "    res = []\n",
    "    for i in range(len(combos)):\n",
    "        combo = combos[i]\n",
    "        label_combo = label_combos[i]\n",
    "        model1_x = combo[0]\n",
    "        model2_x = combo[1]\n",
    "        setup_test_i = lambda yn,xn : setup_test(yn,xn,model1_cov = model1_x, model2_cov= model2_x)\n",
    "        test_stat,res1,res2,res3 = selection_tests.test_results(y_dot,X_dot,setup_test_i)\n",
    "        res.append( [label_combo,test_stat,res1,res2,res3])\n",
    "        print(label_combo,test_stat,res1,res2,res3)\n",
    "    #print_pairwise_tests(res)\n",
    "    return res\n",
    "\n",
    "    \n",
    "res = pairwise_tests(['log_enroll'],model_xs,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e28f747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{ccc|c|ccc}\n",
      "\\toprule\n",
      "{} & \\textbf{Hypotheses} & {} & {}  & {} & \\textbf{p Value}  & {}  \\\\\n",
      "\\textbf{H0} & \\textbf{H1} & \\textbf{H2} & \\textbf{Selection} & \\textbf{Shi (2015)} & \\textbf{Classical} & \\textbf{Bootstrap}\\\\\n",
      "\\midrule\n",
      "$ll1=ll2$ & $ll1>ll2$ & $ll1<ll2$ & $H2$  & $[90,95)$ & $[95,100)$ & $[90,95)$\\\\\n",
      "$ll1=ll3$ & $ll1>ll3$ & $ll1<ll3$ & $H2$  & $-$ & $[95,100)$ & $[90,95)$\\\\\n",
      "$ll1=ll4$ & $ll1>ll4$ & $ll1<ll4$ & $H2$  & $[90,95)$ & $[99,100)$  & $[99,100)$ \\\\\n",
      "$ll2=ll3$ & $ll2>ll3$ & $ll2<ll3$ & $H2$  & $[90,95)$ & $-$ & $[99,100)$ \\\\\n",
      "$ll2=ll4$ & $ll2>ll4$ & $ll2<ll4$ & $H2$  & $-$ & $[95,100)$ & $[90,95)$\\\\\n",
      "$ll3=ll4$ & $ll3>ll4$ & $ll3<ll4$ & $H2$  & $[90,95)$ & $[95,100)$ & $[95,100)$\\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "def print_pairwise_tests(res):\n",
    "    \n",
    "    print('\\\\begin{center}')\n",
    "    print('\\\\begin{tabular}{ccc|c|ccc}')\n",
    "    print('\\\\toprule')\n",
    "    print('{} & \\\\textbf{Hypotheses} & {} & {}  & {} & \\\\textbf{p Value}  & {}  \\\\\\\\')\n",
    "    print('\\\\textbf{H0} & \\\\textbf{H1} & \\\\textbf{H2} & \\\\textbf{Selection} & \\\\textbf{Shi (2015)} & \\\\textbf{Classical} & \\\\textbf{Bootstrap}\\\\\\\\')\n",
    "    print('\\\\midrule')\n",
    "    for row in res:\n",
    "        label_combo,test_stat,classical,shi,boot = row\n",
    "        print( '$%s=%s$ & $%s>%s$ & $%s<%s$ &'%(label_combo+label_combo+label_combo),end='' )\n",
    "        if test_stat > 0:\n",
    "            print(' $H1$ ', end='')\n",
    "        if test_stat <= 0:\n",
    "            print(' $H2$ ',end='')\n",
    "        for sig in [shi,classical,boot]:\n",
    "                \n",
    "            if sig == 85:\n",
    "                print(' & $-$',end='')\n",
    "            if sig == 90:\n",
    "                print( ' & $[90,95)$',end='')\n",
    "            if sig == 95:\n",
    "                print( ' & $[95,100)$',end='')\n",
    "            if sig == 99:\n",
    "                print(' & $[99,100)$ ',end='')\n",
    "        print('\\\\\\\\')\n",
    "    print('\\\\bottomrule')\n",
    "    print('\\\\end{tabular}')\n",
    "    print('\\\\end{center}')\n",
    "\n",
    "print_pairwise_tests(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e69da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511f08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a7e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
